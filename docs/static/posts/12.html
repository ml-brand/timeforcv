<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>CV Time — пост #12</title>
  <meta name="description" content=" Доклады с ECCV 2024? Их есть у нас!    Продолжаем рассказывать о самых интересных статьях, докладах и воркшопах с неё. Вот, что принесли сегодня.    Stable Video 3D   Stability AI предлагает модель i" />
  <link rel="icon" href="../../favicon.ico" sizes="any" />
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32.png" />
  <link rel="apple-touch-icon" href="../../apple-touch-icon.png" />

  <link rel="canonical" href="https://ml-brand.github.io/timeforcv/static/posts/12.html" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="CV Time — пост #12" />
  <meta property="og:description" content=" Доклады с ECCV 2024? Их есть у нас!    Продолжаем рассказывать о самых интересных статьях, докладах и воркшопах с неё. Вот, что принесли сегодня.    Stable Video 3D   Stability AI предлагает модель i" />
  
  <meta property="article:published_time" content="2024-10-03T11:07:02+00:00" />
  <meta property="article:author" content="CV Time" />
  <meta name="twitter:card" content="summary" />
  
  <link rel="stylesheet" href="../../style.css" />
  <script src="../../metrika.js"></script>
</head>
<body data-index-href="../page-4.html">
  <header class="header">
    <div class="container">
      <div class="title-grid single-title">
        <a class="grid-avatar" href="#" target="_blank" rel="noopener">
          <img id="channelAvatar" class="channel-avatar" src="../../assets/channel_avatar.jpg" alt="Аватар канала"  />
        </a>
        <div class="grid-main">
          <div class="title-head">
            <a class="back-link" href="../page-4.html">← Ко всем постам</a>
            <a class="badge-chip" id="siteTitleWrap" href="#" target="_blank" rel="noopener"><h1 id="siteTitle">CV Time</h1></a>
            <div class="hero-actions">
              <a id="subscribeBtn" class="subscribe-btn" href="https://t.me/+JoULEedmHyE5MmYy" target="_blank" rel="noopener" >Подписаться</a>
              <a class="icon-btn" href="../../post.html?id=12" aria-label="Открыть динамическую страницу поста">↺</a>
              <button id="themeToggle" class="icon-btn" type="button" aria-label="Переключить тему"></button>
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>

  
  <div id="promoBanner" class="promo-banner" hidden>
    <div class="container promo-inner">
      <span class="promo-text"><a href="https://t.me/addlist/5NH3RoVejEI1MGEy">Подпишись на все наши ML каналы. Они классные, отвечаем!</a></span>
      <button id="promoClose" class="promo-close" type="button" aria-label="Скрыть плашку">×</button>
    </div>
  </div>
  

  <main class="container single-page">
    <article id="postContainer" class="post post-page" data-post-id="12">
      <div class="post-header">
        <div class="right"><span class="post-date" data-iso-date="2024-10-03T11:07:02+00:00">2024-10-03 11:07 UTC</span></div>
      </div>
      <div class="post-body"><strong>Доклады с ECCV 2024? Их есть у нас! </strong><br><br>Продолжаем рассказывать о самых интересных статьях, докладах и воркшопах с неё. Вот, что принесли сегодня. <br><br><strong>Stable Video 3D</strong><br><br>Stability AI предлагает модель image-to-3d. Они используют image-to-video-модель Stable Video и файнтюнят её на задачу генерации видео с вращением виртуальной камеры вокруг заданного на изображении объекта. Подобно вчерашнему ControlNet Light подходу, здесь добавляют в сам unet сферические параметры камеры в качестве кондишена, а также clip embedding входной картинки. Далее модель обучают на регулярной сетке азимутов и постоянном значении элевации, а только на следующем этапе переходят на непрерывную параметризацию с произвольными значениями. Праеры из Stable Video позволяют получать консистентные novel views. <br><br>Чтобы приблизиться к получению 3D-мэша, авторы предлагают двухэтапный пайплайн: сначала обучить нерф на задачу реконструкции (без SDS) поверх выходов зафайнтьюненной SV под орбитальную съемку на регулярных позах камеры. Затем, уже на втором этапе, используется Masked SDS на непрерывных позах. Причём маскирование происходит по не наблюдаемым с регулярных ракурсов частях мэша. Это важно, чтобы не произошла деградация (блюр) наблюдаемых частей.<br><br>Авторы также говорят о проблемах baked-in lighting. Чтобы их решить, простую illumination-модель обучают на задизентанглинг diffuse color и освещения. Авторы сравнивают multiview-генерации с Zero 1-to-3 и разносят их в одну калитку.<br><br><a href="https://arxiv.org/abs/2403.15378" rel="nofollow noopener noreferrer"><strong>Long-CLIP: Unlocking the Long-Text Capability of CLIP</strong></a><br><br>Сначала авторы определяют, что эффективная длина последовательности в клипе составляет порядка 20 токенов. Этого очень мало для некоторых приложений — например, для ретривала или определения схожести картинки с длинными текстами. А ещё клипы часто используются в качестве текстовых энкодеров для text-conditional генеративных моделей, где такая длина последовательности тоже не достаточна. <br><br>Авторы статьи пробуют дообучить модель на более длинных последовательностях, но главный минус такого подхода — сложности с выделением важного. Модель начинает воспринимать все атрибуты как равно значимые и реагирует на мельчайшие изменения в каждом из них. Чтобы решить эту проблему, авторы предлагают двухэтапный тюнинг:<br><br>1. тюнинг на длинных кепшенах (fine-grained tuning);<br>2. извлечение главных компонентов изображений и текстов с помощью PCA и алайнмент их между собой обычным контрастив-лоссом (coarse-grained tuning). <br><br>В результате модель выдает лучшие показатели и в оценке соответствия длинных текстов изображению, и в качестве текстового энкодера для text2image-диффузии.<br><br><a href="https://arxiv.org/abs/2403.15378" rel="nofollow noopener noreferrer"><strong>VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding</strong></a><br><br>Авторы  предлагают использовать мультимодальный агент для анализа длинных видео. Они наделяют его памятью нескольких типов.<br> <br>Во-первых, это текстовые описания каждого 2-секундного клипа (здесь используют модель LaViLa). Во-вторых, — описания на уровне эмбеддингов: самого клипа (тут берут ViCLIP) и полученного текстового кэпшна (text-embedding-3-large от OpenAI). И память о конкретных затреканных объектах: их эмбеддинги для реидентификации (из CLIP) и моменты появления в видео (отслеживаются ByteTrack) складываются в SQL-базу<br><br>Используя такую память, агент может:<br><br>— описывать 2-секундные фрагменты видео;<br>— искать клип по текстовому запросу с описание происходящего — используются текстовые и видео-фичи клипов, чтобы определить сходство с текстовым запросом; <br>—  отвечать на вопрос по видео — выделяется наиболее релевантный фрагмент и запускается Video-LLaVA;<br>—  рассказывать о качествах конкретных объектов — например, их количестве. Здесь происходит поиск по фичам в трекинговой базе и отправка соответствующего SQL-запроса.<br><br>Агент сам выбирает наиболее подходящее действие с помощью дополнительной LLM. Система выглядит тяжёлой, учитывая то, сколько моделей для неё нужно. Однако она позволяет побить на известных QA-видео-датасетах крутые модели вроде VideoLLaVA, LaViLa и InternVideo.<br><br><em>Разборы подготовили </em><em><tg-emoji emoji-id="5224192932302565805">❣</tg-emoji></em><em> Александр Устюжанин, Сергей Кастрюлин и Дарья Виноградова</em><br><br><a href="https://t.me/+OuN-SY3nIjdlYjli" rel="nofollow noopener noreferrer">CV Time</a><br><br>#YaECCV</div>
      <div class="actions">
        <span>1 367 просмотров · 13 реакций</span>
        <span class="action-links"><a href="https://t.me/timeforcv/12" target="_blank" rel="noopener">Открыть в Telegram</a> · <a href="../page-4.html">К списку постов</a> · <a href="./12.html">Ссылка на этот пост</a></span>
      </div>
    </article>

    <div class="pager single-nav">
      <a id="prevPost" class="nav-link" href="./13.html" style="visibility:visible">← Более новый</a>
      <a id="nextPost" class="nav-link" href="./9.html" style="visibility:visible">Более старый →</a>
    </div>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="footer-inner">
        <span>based on <a href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">tg-to-gh-pages</a> (created by <a href="https://github.com/ml-brand" target="_blank" rel="noopener">ML Brand</a>)</span>
        <a id="repoLink" href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">Do the same with your channel.</a>
        <span class="footer-links">
          static copy ·
          <a href="../../feed.xml" target="_blank" rel="noopener">RSS</a> ·
          <a href="../../atom.xml" target="_blank" rel="noopener">Atom</a>
        </span>
      </div>
    </div>
  </footer>

  <script>
    window.__STATIC_POSTS = [{"id": 12, "media": []}];
    window.__STATIC_META = {"title": "CV Time", "username": "timeforcv", "channel": "timeforcv", "last_sync_utc": "2026-02-11T17:39:52Z", "posts_count": 107, "last_seen_message_id": 239, "stats": {"new": 122, "updated": 16, "media_downloaded": 122}, "avatar": "assets/channel_avatar.jpg", "meta_schema_version": "1.0.0", "posts_schema_version": "1.0.0"};
  </script>
  <script src="../../common.js"></script>
  <script src="../../static.js"></script>
</body>
</html>
