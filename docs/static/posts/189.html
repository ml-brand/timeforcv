<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>CV Time — пост #189</title>
  <meta name="description" content=" Loong: Generating Minute-level Long Videos with Autoregressive Language Models   Сегодня разберём  статью  о Loong — авторегрессионной модели для генерации видео на основе LLM. Архитектура у неё типи" />
  <link rel="icon" href="../../favicon.ico" sizes="any" />
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32.png" />
  <link rel="apple-touch-icon" href="../../apple-touch-icon.png" />

  <link rel="canonical" href="https://ml-brand.github.io/timeforcv/static/posts/189.html" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="CV Time — пост #189" />
  <meta property="og:description" content=" Loong: Generating Minute-level Long Videos with Autoregressive Language Models   Сегодня разберём  статью  о Loong — авторегрессионной модели для генерации видео на основе LLM. Архитектура у неё типи" />
  <meta property="og:image" content="https://ml-brand.github.io/timeforcv/assets/media/189_fish.mp4" />
  <meta property="og:image:alt" content="CV Time" />
  <meta property="article:published_time" content="2025-10-28T12:18:01+00:00" />
  <meta property="article:author" content="CV Time" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:image" content="https://ml-brand.github.io/timeforcv/assets/media/189_fish.mp4" />
  <link rel="stylesheet" href="../../style.css" />
  <script src="../../metrika.js"></script>
</head>
<body data-index-href="../index.html">
  <header class="header">
    <div class="container">
      <div class="title-grid single-title">
        <a class="grid-avatar" href="#" target="_blank" rel="noopener">
          <img id="channelAvatar" class="channel-avatar" src="../../assets/channel_avatar.jpg" alt="Аватар канала"  />
        </a>
        <div class="grid-main">
          <div class="title-head">
            <a class="back-link" href="../index.html">← Ко всем постам</a>
            <a class="badge-chip" id="siteTitleWrap" href="#" target="_blank" rel="noopener"><h1 id="siteTitle">CV Time</h1></a>
            <div class="hero-actions">
              <a id="subscribeBtn" class="subscribe-btn" href="https://t.me/+JoULEedmHyE5MmYy" target="_blank" rel="noopener" >Подписаться</a>
              <a class="icon-btn" href="../../post.html?id=189" aria-label="Открыть динамическую страницу поста">↺</a>
              <button id="themeToggle" class="icon-btn" type="button" aria-label="Переключить тему"></button>
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>

  
  <div id="promoBanner" class="promo-banner" hidden>
    <div class="container promo-inner">
      <span class="promo-text"><a href="https://t.me/addlist/5NH3RoVejEI1MGEy">Подпишись на все наши ML каналы. Они классные, отвечаем!</a></span>
      <button id="promoClose" class="promo-close" type="button" aria-label="Скрыть плашку">×</button>
    </div>
  </div>
  

  <main class="container single-page">
    <article id="postContainer" class="post post-page" data-post-id="189">
      <div class="post-header">
        <div class="right"><span class="post-date" data-iso-date="2025-10-28T12:18:01+00:00">2025-10-28 12:18 UTC</span></div>
      </div>
      <div class="post-body"><strong>Loong: Generating Minute-level Long Videos with Autoregressive Language Models</strong><br><br>Сегодня разберём <a href="https://arxiv.org/abs/2410.02757" rel="nofollow noopener noreferrer">статью</a> о Loong — авторегрессионной модели для генерации видео на основе LLM. Архитектура у неё типичная:<br><br>1. Видео токенизируют. В качестве энкодера использует MAGViT2. Это 3D CNN свёрточная модель, которая обрабатывает темпоральную часть кадров видео, токенизированную с помощью Clustering Vector Quantization. Размер токенайзера — 246M параметров. <br><br>2. Вектора видео подают на вход LLM. Авторы учат с нуля LLaMa от 700M до 7B параметров: 32 000 токенов для текста, 8 192 — для видео и 10 специальных — скорее всего, для разделителей между кадрами. <br><br>3. LLM возвращает другие вектора, на основе которых модель-декодер VQGAN предсказывает изображения — кадры видео. <br><br>Лосс в конце длинной последовательности кадров оказывается меньше, так как видеотокены в одном видео похожи между собой, а модели проще предсказывать похожие токены последовательно. Текстовые токены сильно отличаются от видео: для того чтобы качественно генерировать первые кадры, авторы предлагают перевзвешивать их лосс.<br><br>Обучение делят на три стадии:<br><br><strong>1-я стадия.</strong> Модель предсказывает только одно изображение.<br><strong>2-я стадия.</strong> Генерируется 1 секунда видео и 17 фреймов.<br><strong>3-я стадия.</strong> Самое длинное видео — 10 секунд.<br><br>Модель обучают на десятисекундных видео. Этого мало, если на выходе должно получиться качественное длинное видео. Чтобы повысить качество генерации, авторы предлагают так называемый реинкодинг. То есть, генерировать первые кадры по исходному промпту пользователя. А потом брать в качестве следующего промпта несколько последних кадров получившегося видео и генерировать новое. <br><br>Такой подход замедляет инференс, но снижает требования к обучающему датасету. Loong тренировали на 100M пар «текст + изображение». Для первой стадии использовали датасеты LAION-2B и CC12M. Обучающие видео — 5,5M клипов, отфильтрованных из HDVG.<br><br>Пример Loong подтверждает: генерировать качественные длинные видео можно, даже если обучать модель только на коротких примерах.<br><br>Посмотреть результаты генераций можно на <a href="https://yuqingwang1029.github.io/Loong-video" rel="nofollow noopener noreferrer">GitHub</a>.<br><br><em>Разбор подготовил </em><em><tg-emoji emoji-id="5224192932302565805">❣</tg-emoji></em><em> Андрей Чернов</em><br><a href="https://t.me/+SSca5c9pEyszN2Uy" rel="nofollow noopener noreferrer">CV Time</a><div class="media"><video controls preload="metadata" src="../../assets/media/189_fish.mp4"></video></div></div>
      <div class="actions">
        <span>1 773 просмотров · 24 реакций</span>
        <span class="action-links"><a href="https://t.me/timeforcv/189" target="_blank" rel="noopener">Открыть в Telegram</a> · <a href="../index.html">К списку постов</a> · <a href="./189.html">Ссылка на этот пост</a></span>
      </div>
    </article>

    <div class="pager single-nav">
      <a id="prevPost" class="nav-link" href="./190.html" style="visibility:visible">← Более новый</a>
      <a id="nextPost" class="nav-link" href="./188.html" style="visibility:visible">Более старый →</a>
    </div>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="footer-inner">
        <span>based on <a href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">tg-to-gh-pages</a> (created by <a href="https://github.com/ml-brand" target="_blank" rel="noopener">ML Brand</a>)</span>
        <a id="repoLink" href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">Do the same with your channel.</a>
        <span class="footer-links">
          static copy ·
          <a href="../../feed.xml" target="_blank" rel="noopener">RSS</a> ·
          <a href="../../atom.xml" target="_blank" rel="noopener">Atom</a>
        </span>
      </div>
    </div>
  </footer>

  <script>
    window.__STATIC_POSTS = [{"id": 189, "media": [{"kind": "video", "path": "../../assets/media/189_fish.mp4", "thumb": null, "size": 10144880, "mime": "video/mp4", "name": "fish.mp4"}]}];
    window.__STATIC_META = {"title": "CV Time", "username": "timeforcv", "channel": "timeforcv", "last_sync_utc": "2026-02-10T09:43:24Z", "posts_count": 106, "last_seen_message_id": 237, "stats": {"new": 121, "updated": 8, "media_downloaded": 121}, "avatar": "assets/channel_avatar.jpg", "meta_schema_version": "1.0.0", "posts_schema_version": "1.0.0"};
  </script>
  <script src="../../common.js"></script>
  <script src="../../static.js"></script>
</body>
</html>
