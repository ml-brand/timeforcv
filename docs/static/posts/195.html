<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>CV Time — пост #195</title>
  <meta name="description" content=" NeurIPS 2025 в Мехико идёт полным ходом    Конференция продолжается, а наш коллега Владислав Фахретдинов делится заметками о воркшопе второго дня —  7th International Workshop on Large Scale Holistic" />
  <link rel="icon" href="../../favicon.ico" sizes="any" />
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32.png" />
  <link rel="apple-touch-icon" href="../../apple-touch-icon.png" />

  <link rel="canonical" href="https://ml-brand.github.io/timeforcv/static/posts/195.html" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="CV Time — пост #195" />
  <meta property="og:description" content=" NeurIPS 2025 в Мехико идёт полным ходом    Конференция продолжается, а наш коллега Владислав Фахретдинов делится заметками о воркшопе второго дня —  7th International Workshop on Large Scale Holistic" />
  <meta property="og:image" content="https://ml-brand.github.io/timeforcv/assets/media/thumbs/195_480.webp" />
  <meta property="og:image:alt" content="CV Time" />
  <meta property="article:published_time" content="2025-12-02T13:00:12+00:00" />
  <meta property="article:author" content="CV Time" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:image" content="https://ml-brand.github.io/timeforcv/assets/media/thumbs/195_480.webp" />
  <link rel="stylesheet" href="../../style.css" />
  <script src="../../metrika.js"></script>
</head>
<body data-index-href="../index.html">
  <header class="header">
    <div class="container">
      <div class="title-grid single-title">
        <a class="grid-avatar" href="#" target="_blank" rel="noopener">
          <img id="channelAvatar" class="channel-avatar" src="../../assets/channel_avatar.jpg" alt="Аватар канала"  />
        </a>
        <div class="grid-main">
          <div class="title-head">
            <a class="back-link" href="../index.html">← Ко всем постам</a>
            <a class="badge-chip" id="siteTitleWrap" href="#" target="_blank" rel="noopener"><h1 id="siteTitle">CV Time</h1></a>
            <div class="hero-actions">
              <a id="subscribeBtn" class="subscribe-btn" href="https://t.me/+JoULEedmHyE5MmYy" target="_blank" rel="noopener" >Подписаться</a>
              <a class="icon-btn" href="../../post.html?id=195" aria-label="Открыть динамическую страницу поста">↺</a>
              <button id="themeToggle" class="icon-btn" type="button" aria-label="Переключить тему"></button>
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>

  
  <div id="promoBanner" class="promo-banner" hidden>
    <div class="container promo-inner">
      <span class="promo-text"><a href="https://t.me/addlist/5NH3RoVejEI1MGEy">Подпишись на все наши ML каналы. Они классные, отвечаем!</a></span>
      <button id="promoClose" class="promo-close" type="button" aria-label="Скрыть плашку">×</button>
    </div>
  </div>
  

  <main class="container single-page">
    <article id="postContainer" class="post post-page" data-post-id="195">
      <div class="post-header">
        <div class="right"><span class="post-date" data-iso-date="2025-12-02T13:00:12+00:00">2025-12-02 13:00 UTC</span></div>
      </div>
      <div class="post-body"><strong>NeurIPS 2025 в Мехико идёт полным ходом </strong><br><br>Конференция продолжается, а наш коллега Владислав Фахретдинов делится заметками о воркшопе второго дня — <a href="https://neurips.cc/virtual/2025/loc/mexico-city/workshop/127828" rel="nofollow noopener noreferrer">7th International Workshop on Large Scale Holistic Video Understanding: Toward Video Foundation Models</a>. <br><br><blockquote>Было немного спикеров, но почти каждый привёз по две-три статьи или исследования, поэтому день получился насыщенным. Основной мотив воркшопа — большинство моделей для работы с видео недостаточно хорошо ориентируются «во времени». Участники разбирались, что с этим можно сделать.<br><br>Первым выступил профессор университета Амстердама. Он заметил, что многие VideoLLM не справляются даже с простым синтетическим бенчмарком: какой из двух объектов в видео появляется раньше. Это показывает, что мы до конца не понимаем, как правильно оценивать такие способности модели.<br><br>Затем последовал рассказ о работе Bench of Time с более подробными исследованиями — оказалось, что большинство примеров в популярном бенчмарке (MVBench) решается либо знанием всего об одном кадре, либо вообще исключительно по тексту. Чтобы исправить эту ситуацию, авторы сделали свой бенчмарк TVBench. В нём все вопросы были сформулированы так, что без понимания объектов и процессов в кадре нельзя дать правильный ответ. <br><br>Сравнение моделей на новом бенчмарке показало, что большинство языковых, картиночных и даже видеомоделей выдают результаты немногим лучше случайного предсказания. При этом все же нашлись несколько моделей, которые были достаточно хороши на обоих бенчмарках, например Gemini-1.5.<br><br>Следом было выступление о генерации 3D-представления из изображения. По сути, это продолжение работы <a href="https://arxiv.org/abs/2312.14132" rel="nofollow noopener noreferrer">DUSt3R</a>, в которой научились по любым входным изображениям без параметров камер и поз делать матчинг и генерировать плотное облако точек 3D-представления сцены. <br><br>Авторы сделали уточнение, что матчинг изображений по случайному видео с движением — вычислительно сложная задача. Поэтому они собрали датасет 360-1M, где происходит движение и вращение вокруг оси, из-за чего матчить изображения стало гораздо проще. На основе своего датасета они обучили генеративную модель ODIN, которая по изображению и смещению позиции камеры генерирует новое изображение. Подробностей было мало, никаких сравнений с DUSt3R или NeRF не показали, но зато рассказали, что модель хорошо обобщается вне домена — например, на картины.<br><br>Самый интересный доклад за день — о том, что визуальные модели знают о нашем мире. Авторы выделили и проверили три свойства: базовое представление о физическом устройстве мира, визуальное предсказание, а также обобщение — понимание аналогий.<br><br>Для первого свойства взяли часовые видео с прогулками по городам и с помощью сервиса визуальной локализации, а также небольшого объёма человеческой проверки, разметили эти видео. В частности, для каждого видео сгенерировали маршрут на карте.<br><br>Далее видео нарезали и собрали бенчмарк, в котором модели задавали вопросы по содержанию ролика, например: о евклидовом расстоянии от начальной до конечной точки на полученном маршруте; направлении; зацикленность маршрута; выборе правильного трека на карте среди нескольких вариантов (с текстом на карте и без текста); распознавании окружающей архитектуры. По всем этим вопросам модели уступают человеку — за исключением проверки на зацикленность маршрута.<br><br>Авторы также показали, что на самом деле модели не понимали, был цикл в маршруте или нет. Вместо этого они просто смотрели на разметку на карте и сопоставляли её с текстовыми названиями улиц, которые видны в видео.<br><br>Напоследок был доклад из трёх частей, из которых я бы выделил как самую интересную — SSL-обучение мультимодальной модели видео+аудио CAV-MAE Sync. Из того, что мне кажется важным: авторы совместно используют аудио- и видеопатчи и добавляют регистровый токен, чтобы переносить накопленную информацию в следующие слои. Больше всего мне понравилось, что новая модель позволяет локализовать на видео источники звука.</blockquote><br><br>#YaNeurIPS25<br><br><a href="https://t.me/+SSca5c9pEyszN2Uy" rel="nofollow noopener noreferrer">CV Time</a><div class="media"><img class="media-img" loading="lazy" src="../../assets/media/thumbs/195_480.webp" srcset="../../assets/media/thumbs/195_480.webp 480w, ../../assets/media/195.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="195" data-image-index="0" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/196_480.webp" srcset="../../assets/media/thumbs/196_480.webp 480w, ../../assets/media/196.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="195" data-image-index="1" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/197_480.webp" srcset="../../assets/media/thumbs/197_480.webp 480w, ../../assets/media/197.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="195" data-image-index="2" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/198_480.webp" srcset="../../assets/media/thumbs/198_480.webp 480w, ../../assets/media/198.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="195" data-image-index="3" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/199_480.webp" srcset="../../assets/media/thumbs/199_480.webp 480w, ../../assets/media/199.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="195" data-image-index="4" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/200_480.webp" srcset="../../assets/media/thumbs/200_480.webp 480w, ../../assets/media/200.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="195" data-image-index="5" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/201_480.webp" srcset="../../assets/media/thumbs/201_480.webp 480w, ../../assets/media/201.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="195" data-image-index="6" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/202_480.webp" srcset="../../assets/media/thumbs/202_480.webp 480w, ../../assets/media/202.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="195" data-image-index="7" /></div></div>
      <div class="actions">
        <span>1 142 просмотров · 27 реакций</span>
        <span class="action-links"><a href="https://t.me/timeforcv/195" target="_blank" rel="noopener">Открыть в Telegram</a> · <a href="../index.html">К списку постов</a> · <a href="./195.html">Ссылка на этот пост</a></span>
      </div>
    </article>

    <div class="pager single-nav">
      <a id="prevPost" class="nav-link" href="./203.html" style="visibility:visible">← Более новый</a>
      <a id="nextPost" class="nav-link" href="./194.html" style="visibility:visible">Более старый →</a>
    </div>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="footer-inner">
        <span>based on <a href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">tg-to-gh-pages</a> (created by <a href="https://github.com/ml-brand" target="_blank" rel="noopener">ML Brand</a>)</span>
        <a id="repoLink" href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">Do the same with your channel.</a>
        <span class="footer-links">
          static copy ·
          <a href="../../feed.xml" target="_blank" rel="noopener">RSS</a> ·
          <a href="../../atom.xml" target="_blank" rel="noopener">Atom</a>
        </span>
      </div>
    </div>
  </footer>

  <script>
    window.__STATIC_POSTS = [{"id": 195, "media": [{"kind": "photo", "path": "../../assets/media/195.jpg", "thumb": "../../assets/media/thumbs/195_480.webp", "size": 106022, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/196.jpg", "thumb": "../../assets/media/thumbs/196_480.webp", "size": 80551, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/197.jpg", "thumb": "../../assets/media/thumbs/197_480.webp", "size": 73777, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/198.jpg", "thumb": "../../assets/media/thumbs/198_480.webp", "size": 69597, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/199.jpg", "thumb": "../../assets/media/thumbs/199_480.webp", "size": 120976, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/200.jpg", "thumb": "../../assets/media/thumbs/200_480.webp", "size": 74039, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/201.jpg", "thumb": "../../assets/media/thumbs/201_480.webp", "size": 90234, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/202.jpg", "thumb": "../../assets/media/thumbs/202_480.webp", "size": 96401, "mime": "image/jpeg", "name": null}]}];
    window.__STATIC_META = {"title": "CV Time", "username": "timeforcv", "channel": "timeforcv", "last_sync_utc": "2026-02-13T09:28:10Z", "posts_count": 107, "last_seen_message_id": 239, "stats": {"new": 122, "updated": 15, "media_downloaded": 122}, "avatar": "assets/channel_avatar.jpg", "meta_schema_version": "1.0.0", "posts_schema_version": "1.0.0"};
  </script>
  <script src="../../common.js"></script>
  <script src="../../static.js"></script>
</body>
</html>
